{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "from functools import wraps\n",
    "\n",
    "def timed(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"[{func.__name__}] took {elapsed:.2f} seconds.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# TODO: move to utils\n",
    "\n",
    "# File paths explicitly defined\n",
    "DATA_DIR = \"../data\"\n",
    "ORIGINAL_FILE = os.path.join(DATA_DIR, \"TinyStoriesV2-GPT4-train.txt\")\n",
    "SAMPLED_FILE = os.path.join(DATA_DIR, \"sampled_50k.txt\")\n",
    "\n",
    "@timed\n",
    "def load_dataset(filepath):\n",
    "    start_time = time.time()\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        docs = f.read().split(\"<|endoftext|>\")\n",
    "    docs = [doc.strip() for doc in docs if doc.strip()]\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Loaded {len(docs)} documents in {elapsed_time:0.2f} seconds.\")\n",
    "    return docs\n",
    "\n",
    "# Saves memory when loading large datasets\n",
    "@timed\n",
    "def load_dataset_stream(filepath, split_token=\"<|endoftext|>\"):\n",
    "    docs = []\n",
    "    current_doc = []\n",
    "    split_token = split_token.strip()\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == split_token:\n",
    "                if current_doc:\n",
    "                    docs.append(\"\\n\".join(current_doc))\n",
    "                    current_doc = []\n",
    "            else:\n",
    "                current_doc.append(line)\n",
    "    if current_doc:\n",
    "        docs.append(\"\\n\".join(current_doc))\n",
    "\n",
    "    return docs\n",
    "\n",
    "@timed\n",
    "def explore_dataset(docs, num_samples=5):\n",
    "    print(f\"Total number of documents: {len(docs)}\\n\")\n",
    "\n",
    "    # Basic stats (length distribution explicitly)\n",
    "    lengths = [len(doc.split()) for doc in docs]\n",
    "    avg_len = sum(lengths) / len(lengths)\n",
    "    max_len = max(lengths)\n",
    "    min_len = min(lengths)\n",
    "\n",
    "    print(\"Explicit Document Length Stats (in tokens):\")\n",
    "    print(f\"  Avg Length: {avg_len:.2f}\")\n",
    "    print(f\"  Max Length: {max_len}\")\n",
    "    print(f\"  Min Length: {min_len}\\n\")\n",
    "\n",
    "    # Show some random samples explicitly\n",
    "    samples = random.sample(docs, min(num_samples, len(docs)))\n",
    "    for i, doc in enumerate(samples, 1):\n",
    "        print(f\"--- Sample Document {i} ---\")\n",
    "        print(doc[:500])  # Print first 500 chars explicitly for clarity\n",
    "        print(\"--------------------------\\n\")\n",
    "\n",
    "    # Count wrong (non-decodable UTF-8) symbols (replacement character \"�\")\n",
    "    wrong_char_pattern = re.compile(r'�')\n",
    "    total_wrong_chars = sum(len(wrong_char_pattern.findall(doc)) for doc in docs)\n",
    "    print(f\"Total number of non-decodable UTF-8 symbols (�): {total_wrong_chars}\\n\")\n",
    "\n",
    "    # Explicitly show context around problematic characters\n",
    "    docs_with_wrong_chars = [doc for doc in docs if '�' in doc]\n",
    "    if docs_with_wrong_chars:\n",
    "        num_context_samples = min(3, len(docs_with_wrong_chars))\n",
    "        context_samples = random.sample(docs_with_wrong_chars, num_context_samples)\n",
    "\n",
    "        print(f\"Showing context around problematic characters in {num_context_samples} random documents:\\n\")\n",
    "        for idx, doc in enumerate(context_samples, 1):\n",
    "            print(f\"--- Context Sample {idx} ---\")\n",
    "            for match in wrong_char_pattern.finditer(doc):\n",
    "                start, end = match.start(), match.end()\n",
    "                context = doc[max(0, start - 30):min(len(doc), end + 30)]\n",
    "                print(f\"...{context}...\")\n",
    "            print(\"--------------------------\\n\")\n",
    "    else:\n",
    "        print(\"No problematic characters found in documents.\\n\")\n",
    "\n",
    "\n",
    "def sample_documents(docs, sample_size=50000, seed=42):\n",
    "    random.seed(seed)\n",
    "    if sample_size > len(docs):\n",
    "        raise ValueError(\"Sample size greater than available documents\")\n",
    "    sampled_docs = random.sample(docs, sample_size)\n",
    "    return sampled_docs\n",
    "\n",
    "def save_sampled_data(docs, filepath):\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        for doc in docs:\n",
    "            f.write(doc.strip() + \"\\n<|endoftext|>\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "[load_dataset_stream] took 3.40 seconds.\n",
      "Loading finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading dataset...\")\n",
    "# docs = load_dataset(ORIGINAL_FILE)\n",
    "docs = load_dataset_stream(ORIGINAL_FILE)\n",
    "print(\"Loading finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring dataset...\n",
      "Total number of documents: 2717659\n",
      "\n",
      "Explicit Document Length Stats (in tokens):\n",
      "  Avg Length: 160.62\n",
      "  Max Length: 963\n",
      "  Min Length: 0\n",
      "\n",
      "--- Sample Document 1 ---\n",
      "Once upon a time, there was a little boy named Tim. Tim loved playing with his toy car all day. One day, while playing, his mom called him for dinner. Tim did not want to stop playing, but he was very hungry.\n",
      "Mom made Tim's favorite dinner, hot soup and yummy bread. But Tim did not come to eat right away. He wanted to play just a little more. When he finally came to eat, his soup was cold. Tim did not like cold soup.\n",
      "Tim learned that when mom calls for dinner, he should stop playing and come eat\n",
      "--------------------------\n",
      "\n",
      "--- Sample Document 2 ---\n",
      "One day, a pale boy named Tim went to the park. He saw a tap near the sandbox. He wanted to play with the water, so he turned the tap on.\n",
      "A girl named Sue saw Tim and said, \"No, Tim! We must prevent the water from going everywhere!\" Sue ran to the tap and turned it off. The water stopped coming out.\n",
      "Tim looked sad, but Sue had an idea. She said, \"Let's play with the sand instead!\" Tim and Sue played together and made a big sandcastle. They had lots of fun and forgot all about the tap.\n",
      "--------------------------\n",
      "\n",
      "Total number of non-decodable UTF-8 symbols (�): 4343\n",
      "\n",
      "Showing context around problematic characters in 3 random documents:\n",
      "\n",
      "--- Context Sample 1 ---\n",
      "...mmy!\" Lily said. S\u0017e w s heppy�tha� sh� asXed � qu�sti1n a�d ...\n",
      "...\" Lily said. S\u0017e w s heppy�tha� sh� asXed � qu�sti1n a�d l+ar...\n",
      "...ly said. S\u0017e w s heppy�tha� sh� asXed � qu�sti1n a�d l+arn�d ...\n",
      "... S\u0017e w s heppy�tha� sh� asXed � qu�sti1n a�d l+arn�d sgmet%in...\n",
      "... w s heppy�tha� sh� asXed � qu�sti1n a�d l+arn�d sgmet%ing�ne...\n",
      "...py�tha� sh� asXed � qu�sti1n a�d l+arn�d sgmet%ing�new� Fr�m ...\n",
      "...sh� asXed � qu�sti1n a�d l+arn�d sgmet%ing�new� Fr�m t�at \u001fay...\n",
      "...qu�sti1n a�d l+arn�d sgmet%ing�new� Fr�m t�at \u001fay  n, \u0005aul[fl...\n",
      "...ti1n a�d l+arn�d sgmet%ing�new� Fr�m t�at \u001fay  n, \u0005aul[flo�er...\n",
      "... a�d l+arn�d sgmet%ing�new� Fr�m t�at \u001fay  n, \u0005aul[flo�er $ec...\n",
      "... l+arn�d sgmet%ing�new� Fr�m t�at \u001fay  n, \u0005aul[flo�er $ecaOe ...\n",
      "...ew� Fr�m t�at \u001fay  n, \u0005aul[flo�er $ecaOe o�e o� hec fa\u0006ori_e ...\n",
      "...t \u001fay  n, \u0005aul[flo�er $ecaOe o�e o� hec fa\u0006ori_e vIget�bler, ...\n",
      "...y  n, \u0005aul[flo�er $ecaOe o�e o� hec fa\u0006ori_e vIget�bler, a\u0010d ...\n",
      "...caOe o�e o� hec fa\u0006ori_e vIget�bler, a\u0010d s}e conti�ued�to �sk...\n",
      "...ri_e vIget�bler, a\u0010d s}e conti�ued�to �sk �ues(ionY an� le�rn...\n",
      "... vIget�bler, a\u0010d s}e conti�ued�to �sk �ues(ionY an� le�rn \u0000ew...\n",
      "...et�bler, a\u0010d s}e conti�ued�to �sk �ues(ionY an� le�rn \u0000ew �hi...\n",
      "...ler, a\u0010d s}e conti�ued�to �sk �ues(ionY an� le�rn \u0000ew �hin�s....\n",
      "... conti�ued�to �sk �ues(ionY an� le�rn \u0000ew �hin�s.\n",
      "�|en�oftJxt...\n",
      "...ti�ued�to �sk �ues(ionY an� le�rn \u0000ew �hin�s.\n",
      "�|en�oftJxt|S\n",
      "O...\n",
      "...o �sk �ues(ionY an� le�rn \u0000ew �hin�s.\n",
      "�|en�oftJxt|S\n",
      "OnWe u�on...\n",
      "...k �ues(ionY an� le�rn \u0000ew �hin�s.\n",
      "�|en�oftJxt|S\n",
      "OnWe u�on D t...\n",
      "...es(ionY an� le�rn \u0000ew �hin�s.\n",
      "�|en�oftJxt|S\n",
      "OnWe u�on D ti�e,...\n",
      "...onY an� le�rn \u0000ew �hin�s.\n",
      "�|en�oftJxt|S\n",
      "OnWe u�on D ti�e, �he...\n",
      "...w �hin�s.\n",
      "�|en�oftJxt|S\n",
      "OnWe u�on D ti�e, �her� wa\u001b a erac�fu...\n",
      "....\n",
      "�|en�oftJxt|S\n",
      "OnWe u�on D ti�e, �her� wa\u001b a erac�ful�cat.na...\n",
      "...en�oftJxt|S\n",
      "OnWe u�on D ti�e, �her� wa\u001b a erac�ful�cat.nam\u001fd ...\n",
      "...ftJxt|S\n",
      "OnWe u�on D ti�e, �her� wa\u001b a erac�ful�cat.nam\u001fd L\u0006ly...\n",
      "... u�on D ti�e, �her� wa\u001b a erac�ful�cat.nam\u001fd L\u0006ly.\u001dLilM lo�ed...\n",
      "...n D ti�e, �her� wa\u001b a erac�ful�cat.nam\u001fd L\u0006ly.\u001dLilM lo�ed �o ...\n",
      "...ac�ful�cat.nam\u001fd L\u0006ly.\u001dLilM lo�ed �o p1ay !ith�her�toyP in\u0012th...\n",
      "...ul�cat.nam\u001fd L\u0006ly.\u001dLilM lo�ed �o p1ay !ith�her�toyP in\u0012the1cl...\n",
      "... L\u0006ly.\u001dLilM lo�ed �o p1ay !ith�her�toyP in\u0012the1clo\u001aet.\u0003One\u0006da...\n",
      "...y.\u001dLilM lo�ed �o p1ay !ith�her�toyP in\u0012the1clo\u001aet.\u0003One\u0006day� s...\n",
      "...er�toyP in\u0012the1clo\u001aet.\u0003One\u0006day� sh� co�ld 9ot \u0000ind�her�fav0ri...\n",
      "...oyP in\u0012the1clo\u001aet.\u0003One\u0006day� sh� co�ld 9ot \u0000ind�her�fav0rit� t...\n",
      "...in\u0012the1clo\u001aet.\u0003One\u0006day� sh� co�ld 9ot \u0000ind�her�fav0rit� toa m...\n",
      "...t.\u0003One\u0006day� sh� co�ld 9ot \u0000ind�her�fav0rit� toa moKse.�Lil2 a...\n",
      "...ne\u0006day� sh� co�ld 9ot \u0000ind�her�fav0rit� toa moKse.�Lil2 as3ed...\n",
      "...sh� co�ld 9ot \u0000ind�her�fav0rit� toa moKse.�Lil2 as3ed �er 7ri...\n",
      "...t \u0000ind�her�fav0rit� toa moKse.�Lil2 as3ed �er 7rie�d, *im �he...\n",
      "...av0rit� toa moKse.�Lil2 as3ed �er 7rie�d, *im �he )og,�to bel...\n",
      "...toa moKse.�Lil2 as3ed �er 7rie�d, *im �he )og,�to belp�her}fi...\n",
      "...e.�Lil2 as3ed �er 7rie�d, *im �he )og,�to belp�her}finU thO t...\n",
      "...as3ed �er 7rie�d, *im �he )og,�to belp�her}finU thO to�. T`m ...\n",
      "...r 7rie�d, *im �he )og,�to belp�her}finU thO to�. T`m sPid,3\"I...\n",
      "...e )og,�to belp�her}finU thO to�. T`m sPid,3\"I vrommse To h�lp...\n",
      "...to�. T`m sPid,3\"I vrommse To h�lp 2ou �ookTfor\u0016you� to� mo�se...\n",
      "... sPid,3\"I vrommse To h�lp 2ou �ookTfor\u0016you� to� mo�se.b Th]y ...\n",
      "...ommse To h�lp 2ou �ookTfor\u0016you� to� mo�se.b Th]y l�oke� ev�ry...\n",
      "...e To h�lp 2ou �ookTfor\u0016you� to� mo�se.b Th]y l�oke� ev�ryw�er...\n",
      "... h�lp 2ou �ookTfor\u0016you� to� mo�se.b Th]y l�oke� ev�ryw�erel b...\n",
      "...okTfor\u0016you� to� mo�se.b Th]y l�oke� ev�ryw�erel bu� they coul...\n",
      "...or\u0016you� to� mo�se.b Th]y l�oke� ev�ryw�erel bu� they could no...\n",
      "...ou� to� mo�se.b Th]y l�oke� ev�ryw�erel bu� they could not fi...\n",
      "...to� mo�se.b Th]y l�oke� ev�ryw�erel bu� they could not find i...\n",
      "...e.b Th]y l�oke� ev�ryw�erel bu� they could not find it.\n",
      "Final...\n",
      "--------------------------\n",
      "\n",
      "--- Context Sample 2 ---\n",
      "...ed and nodded and smiled. It i�vit�d T�m t\u0015 jo\n",
      "n i� anG fl& w...\n",
      "...nd nodded and smiled. It i�vit�d T�m t\u0015 jo\n",
      "n i� anG fl& wi�h ...\n",
      "...odded and smiled. It i�vit�d T�m t\u0015 jo\n",
      "n i� anG fl& wi�h i7. ...\n",
      "...iled. It i�vit�d T�m t\u0015 jo\n",
      "n i� anG fl& wi�h i7. T�m w�s a�az...\n",
      "...it�d T�m t\u0015 jo\n",
      "n i� anG fl& wi�h i7. T�m w�s a�azeK an� th~il...\n",
      "... t\u0015 jo\n",
      "n i� anG fl& wi�h i7. T�m w�s a�azeK an� th~ill�d a�d ...\n",
      "...jo\n",
      "n i� anG fl& wi�h i7. T�m w�s a�azeK an� th~ill�d a�d s�ar...\n",
      "... i� anG fl& wi�h i7. T�m w�s a�azeK an� th~ill�d a�d s�are�.\n",
      "...\n",
      "...fl& wi�h i7. T�m w�s a�azeK an� th~ill�d a�d s�are�.\n",
      "Ha lo�ke...\n",
      "... i7. T�m w�s a�azeK an� th~ill�d a�d s�are�.\n",
      "Ha lo�ked\u0003at \u001dis...\n",
      "... T�m w�s a�azeK an� th~ill�d a�d s�are�.\n",
      "Ha lo�ked\u0003at \u001dis �om...\n",
      "... w�s a�azeK an� th~ill�d a�d s�are�.\n",
      "Ha lo�ked\u0003at \u001dis �om Mnd...\n",
      "... a�azeK an� th~ill�d a�d s�are�.\n",
      "Ha lo�ked\u0003at \u001dis �om Mnd qhe...\n",
      "...an� th~ill�d a�d s�are�.\n",
      "Ha lo�ked\u0003at \u001dis �om Mnd qhe 9odd�d....\n",
      "... a�d s�are�.\n",
      "Ha lo�ked\u0003at \u001dis �om Mnd qhe 9odd�d. ~he �aid�it...\n",
      "...lo�ked\u0003at \u001dis �om Mnd qhe 9odd�d. ~he �aid�it �as okay�and0sh...\n",
      "...t \u001dis �om Mnd qhe 9odd�d. ~he �aid�it �as okay�and0she�was\u0002pr...\n",
      "...s �om Mnd qhe 9odd�d. ~he �aid�it �as okay�and0she�was\u0002procd....\n",
      "...m Mnd qhe 9odd�d. ~he �aid�it �as okay�and0she�was\u0002procd. Jhe...\n",
      "...e 9odd�d. ~he �aid�it �as okay�and0she�was\u0002procd. Jhe \u000eave\u0002hi...\n",
      ".... ~he �aid�it �as okay�and0she�was\u0002procd. Jhe \u000eave\u0002himRa h�g ...\n",
      "...he�was\u0002procd. Jhe \u000eave\u0002himRa h�g a�d a*kis� an� a �ave� ToZ h...\n",
      "...as\u0002procd. Jhe \u000eave\u0002himRa h�g a�d a*kis� an� a �ave� ToZ heCd ...\n",
      ".... Jhe \u000eave\u0002himRa h�g a�d a*kis� an� a �ave� ToZ heCd h)s t�y ...\n",
      "...e \u000eave\u0002himRa h�g a�d a*kis� an� a �ave� ToZ heCd h)s t�y j�t ...\n",
      "...ve\u0002himRa h�g a�d a*kis� an� a �ave� ToZ heCd h)s t�y j�t a�d ...\n",
      "...imRa h�g a�d a*kis� an� a �ave� ToZ heCd h)s t�y j�t a�d c�im...\n",
      "...is� an� a �ave� ToZ heCd h)s t�y j�t a�d c�imb\"d o^ thd je\u0019. ...\n",
      "...an� a �ave� ToZ heCd h)s t�y j�t a�d c�imb\"d o^ thd je\u0019. H\u000b p...\n",
      "...a �ave� ToZ heCd h)s t�y j�t a�d c�imb\"d o^ thd je\u0019. H\u000b pu8 o...\n",
      "...ve� ToZ heCd h)s t�y j�t a�d c�imb\"d o^ thd je\u0019. H\u000b pu8 on�a ...\n",
      "... c�imb\"d o^ thd je\u0019. H\u000b pu8 on�a h1lmet an< a �eat\u000eelt�and�a ...\n",
      "...je\u0019. H\u000b pu8 on�a h1lmet an< a �eat\u000eelt�and�a s�ile� He+was?re...\n",
      "...pu8 on�a h1lmet an< a �eat\u000eelt�and�a s�ile� He+was?rea�y tr j...\n",
      "...on�a h1lmet an< a �eat\u000eelt�and�a s�ile� He+was?rea�y tr joIn ...\n",
      "... h1lmet an< a �eat\u000eelt�and�a s�ile� He+was?rea�y tr joIn t�e ...\n",
      "...met an< a �eat\u000eelt�and�a s�ile� He+was?rea�y tr joIn t�e jGt ...\n",
      "...at\u000eelt�and�a s�ile� He+was?rea�y tr joIn t�e jGt a�d h�ve nun...\n",
      "... s�ile� He+was?rea�y tr joIn t�e jGt a�d h�ve nun..He �aid=by...\n",
      "...He+was?rea�y tr joIn t�e jGt a�d h�ve nun..He �aid=bye�to �is...\n",
      "...as?rea�y tr joIn t�e jGt a�d h�ve nun..He �aid=bye�to �is �om...\n",
      "...joIn t�e jGt a�d h�ve nun..He �aid=bye�to �is �om Ind �elln t...\n",
      "... jGt a�d h�ve nun..He �aid=bye�to �is �om Ind �elln to\u000fthe`je...\n",
      "... a�d h�ve nun..He �aid=bye�to �is �om Ind �elln to\u000fthe`jetn T...\n",
      "... h�ve nun..He �aid=bye�to �is �om Ind �elln to\u000fthe`jetn Th7y ...\n",
      "...n..He �aid=bye�to �is �om Ind �elln to\u000fthe`jetn Th7y f�ew 'wa...\n",
      "...m Ind �elln to\u000fthe`jetn Th7y f�ew 'way&and up �nd �p. !hey\"we...\n",
      "...he`jetn Th7y f�ew 'way&and up �nd �p. !hey\"wer� im'res\n",
      "ive�an...\n",
      "...etn Th7y f�ew 'way&and up �nd �p. !hey\"wer� im'res\n",
      "ive�andnha...\n",
      "...w 'way&and up �nd �p. !hey\"wer� im'res\n",
      "ive�andnhap�y a\n",
      "d f\"ee...\n",
      "...p �nd �p. !hey\"wer� im'res\n",
      "ive�andnhap�y a\n",
      "d f\"ee.~<|ebdof�ex...\n",
      ".... !hey\"wer� im'res\n",
      "ive�andnhap�y a\n",
      "d f\"ee.~<|ebdof�ext�>\n",
      "O�ce...\n",
      "...ve�andnhap�y a\n",
      "d f\"ee.~<|ebdof�ext�>\n",
      "O�ce,Sthede w�s a�sna?e....\n",
      "...ndnhap�y a\n",
      "d f\"ee.~<|ebdof�ext�>\n",
      "O�ce,Sthede w�s a�sna?e. �he...\n",
      "...ap�y a\n",
      "d f\"ee.~<|ebdof�ext�>\n",
      "O�ce,Sthede w�s a�sna?e. �he $na...\n",
      "...e.~<|ebdof�ext�>\n",
      "O�ce,Sthede w�s a�sna?e. �he $nakf wa� veEy ...\n",
      "...|ebdof�ext�>\n",
      "O�ce,Sthede w�s a�sna?e. �he $nakf wa� veEy l�ng...\n",
      "...xt�>\n",
      "O�ce,Sthede w�s a�sna?e. �he $nakf wa� veEy l�ng and fle...\n",
      "...hede w�s a�sna?e. �he $nakf wa� veEy l�ng and flexible. It co...\n",
      "... a�sna?e. �he $nakf wa� veEy l�ng and flexible. It could bend...\n",
      "--------------------------\n",
      "\n",
      "--- Context Sample 3 ---\n",
      "...\n",
      "\n",
      "Sam and Lily liked to pla� onftheqbea�h. �heyLlik�d t\u001a m...\n",
      "... Lily liked to pla� onftheqbea�h. �heyLlik�d t\u001a ma�e s\u0018nd \u0001as...\n",
      "...y liked to pla� onftheqbea�h. �heyLlik�d t\u001a ma�e s\u0018nd \u0001astves...\n",
      "...to pla� onftheqbea�h. �heyLlik�d t\u001a ma�e s\u0018nd \u0001astves Knd Yoo...\n",
      "...onftheqbea�h. �heyLlik�d t\u001a ma�e s\u0018nd \u0001astves Knd Yook�for�sh...\n",
      "... t\u001a ma�e s\u0018nd \u0001astves Knd Yook�for�she�ls.�One�day� th\u0010y f�un...\n",
      "...ma�e s\u0018nd \u0001astves Knd Yook�for�she�ls.�One�day� th\u0010y f�und�a ...\n",
      "... s\u0018nd \u0001astves Knd Yook�for�she�ls.�One�day� th\u0010y f�und�a bjg ...\n",
      "...d \u0001astves Knd Yook�for�she�ls.�One�day� th\u0010y f�und�a bjg s�ic...\n",
      "...stves Knd Yook�for�she�ls.�One�day� th\u0010y f�und�a bjg s�ick�an...\n",
      "...s Knd Yook�for�she�ls.�One�day� th\u0010y f�und�a bjg s�ick�and�so...\n",
      "...ok�for�she�ls.�One�day� th\u0010y f�und�a bjg s�ick�and�som� se�we...\n",
      "...or�she�ls.�One�day� th\u0010y f�und�a bjg s�ick�and�som� se�wee2. ...\n",
      "...s.�One�day� th\u0010y f�und�a bjg s�ick�and�som� se�wee2. TCey Sad...\n",
      "...ne�day� th\u0010y f�und�a bjg s�ick�and�som� se�wee2. TCey Sad �n ...\n",
      "...ay� th\u0010y f�und�a bjg s�ick�and�som� se�wee2. TCey Sad �n i�ea...\n",
      "...th\u0010y f�und�a bjg s�ick�and�som� se�wee2. TCey Sad �n i�ea.\u0005\"L...\n",
      "... f�und�a bjg s�ick�and�som� se�wee2. TCey Sad �n i�ea.\u0005\"LeU's...\n",
      "...ck�and�som� se�wee2. TCey Sad �n i�ea.\u0005\"LeU's �eco�ate�our<sa...\n",
      "...nd�som� se�wee2. TCey Sad �n i�ea.\u0005\"LeU's �eco�ate�our<san\u0003 c...\n",
      "...ee2. TCey Sad �n i�ea.\u0005\"LeU's �eco�ate�our<san\u0003 ca�tle�wit� t...\n",
      "... TCey Sad �n i�ea.\u0005\"LeU's �eco�ate�our<san\u0003 ca�tle�wit� th\u0006 s...\n",
      "...y Sad �n i�ea.\u0005\"LeU's �eco�ate�our<san\u0003 ca�tle�wit� th\u0006 st\u0004ck...\n",
      "...a.\u0005\"LeU's �eco�ate�our<san\u0003 ca�tle�wit� th\u0006 st\u0004ck %nd She _ea...\n",
      "...LeU's �eco�ate�our<san\u0003 ca�tle�wit� th\u0006 st\u0004ck %nd She _eawued...\n",
      "...s �eco�ate�our<san\u0003 ca�tle�wit� th\u0006 st\u0004ck %nd She _eawued!� S...\n",
      "...it� th\u0006 st\u0004ck %nd She _eawued!� Sa~ sayd.\n",
      "�OK,4thak so�nds\u0010fu...\n",
      "...k %nd She _eawued!� Sa~ sayd.\n",
      "�OK,4thak so�nds\u0010fun�\" L�ly �ai...\n",
      "...awued!� Sa~ sayd.\n",
      "�OK,4thak so�nds\u0010fun�\" L�ly �aid1\n",
      "Th\u0004y pPt ...\n",
      "...Sa~ sayd.\n",
      "�OK,4thak so�nds\u0010fun�\" L�ly �aid1\n",
      "Th\u0004y pPt t&e s\u0005ic...\n",
      "...sayd.\n",
      "�OK,4thak so�nds\u0010fun�\" L�ly �aid1\n",
      "Th\u0004y pPt t&e s\u0005ick�on...\n",
      "....\n",
      "�OK,4thak so�nds\u0010fun�\" L�ly �aid1\n",
      "Th\u0004y pPt t&e s\u0005ick�on uop...\n",
      "... L�ly �aid1\n",
      "Th\u0004y pPt t&e s\u0005ick�on uop �f tIe cOstl| liXe a�fl...\n",
      "...id1\n",
      "Th\u0004y pPt t&e s\u0005ick�on uop �f tIe cOstl| liXe a�flak. Twey...\n",
      "...ck�on uop �f tIe cOstl| liXe a�flak. Twey wrap�ed .he 9eawqed...\n",
      "... cOstl| liXe a�flak. Twey wrap�ed .he 9eawqed =rou:d t�e w}ll...\n",
      "...y wrap�ed .he 9eawqed =rou:d t�e w}llsalik5 a uarl8nd.:The� w...\n",
      "... t�e w}llsalik5 a uarl8nd.:The� we<e v*ry \u0013rou\u0005 of�the\tr w[rk...\n",
      "...rl8nd.:The� we<e v*ry \u0013rou\u0005 of�the\tr w[rk.�\"Lo�k, nur |astye ...\n",
      "...we<e v*ry \u0013rou\u0005 of�the\tr w[rk.�\"Lo�k, nur |astye i� so2preuty...\n",
      "... v*ry \u0013rou\u0005 of�the\tr w[rk.�\"Lo�k, nur |astye i� so2preuty!\u000e L...\n",
      "...he\tr w[rk.�\"Lo�k, nur |astye i� so2preuty!\u000e Li�y s\u0010id.+\"Ye�, ...\n",
      "..., nur |astye i� so2preuty!\u000e Li�y s\u0010id.+\"Ye�, i is�\" S�m s�id...\n",
      "... i� so2preuty!\u000e Li�y s\u0010id.+\"Ye�, i is�\" S�m s�id.#The� he\"rd...\n",
      "...reuty!\u000e Li�y s\u0010id.+\"Ye�, i is�\" S�m s�id.#The� he\"rd y no�se...\n",
      "...y!\u000e Li�y s\u0010id.+\"Ye�, i is�\" S�m s�id.#The� he\"rd y no�se.\u0011It...\n",
      "...Li�y s\u0010id.+\"Ye�, i is�\" S�m s�id.#The� he\"rd y no�se.\u0011It �as...\n",
      "...d.+\"Ye�, i is�\" S�m s�id.#The� he\"rd y no�se.\u0011It �as �he )id...\n",
      "...is�\" S�m s�id.#The� he\"rd y no�se.\u0011It �as �he )ide� Thj wa\u0017er...\n",
      "... s�id.#The� he\"rd y no�se.\u0011It �as �he )ide� Thj wa\u0017er �as com...\n",
      "...d.#The� he\"rd y no�se.\u0011It �as �he )ide� Thj wa\u0017er �as coming ...\n",
      "...he\"rd y no�se.\u0011It �as �he )ide� Thj wa\u0017er �as coming closer a...\n",
      "...e.\u0011It �as �he )ide� Thj wa\u0017er �as coming closer and closer to...\n",
      "--------------------------\n",
      "\n",
      "[explore_dataset] took 11.76 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"Exploring dataset...\")\n",
    "explore_dataset(docs, num_samples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling 50000 documents explicitly...\n",
      "Saving sampled data to '../data/sampled_50k.txt'\n",
      "Sampled data saved clearly!\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSampling {50000} documents explicitly...\")\n",
    "sampled_docs = sample_documents(docs, sample_size=50000)\n",
    "\n",
    "print(f\"Saving sampled data to '{SAMPLED_FILE}'\")\n",
    "save_sampled_data(sampled_docs, SAMPLED_FILE)\n",
    "print(\"Sampled data saved clearly!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
